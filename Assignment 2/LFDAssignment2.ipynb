{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(corpus_file, use_sentiment):\n",
    "    documents = []\n",
    "    labels = []\n",
    "    with open(corpus_file, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            \n",
    "            tokens = line.strip().split()\n",
    "            \n",
    "            #replace all numbers to the string 'number' \n",
    "            new_tokens = []\n",
    "            for token in tokens: \n",
    "                if token.isdigit():\n",
    "                    new_tokens.append('digit')\n",
    "                else:\n",
    "                    new_tokens.append(token)\n",
    "            tokens = new_tokens\n",
    "                    \n",
    "            # remove stopwords\n",
    "            from nltk.corpus import stopwords\n",
    "            stop = stopwords.words('english')\n",
    "            tokens = [token for token in tokens if token not in stop]\n",
    "            \n",
    "            # porter stemming\n",
    "            from nltk.stem.porter import PorterStemmer\n",
    "            st = PorterStemmer()\n",
    "            tokens = [st.stem(word) for word in tokens]\n",
    "            \n",
    "            documents.append(tokens[3:])\n",
    "\n",
    "            if use_sentiment:\n",
    "                # 2-class problem: positive vs negative\n",
    "                labels.append( tokens[1] )\n",
    "            else:\n",
    "                # 6-class problem: books, camera, dvd, health, music, software\n",
    "                labels.append( tokens[0] )\n",
    "\n",
    "    return documents, labels\n",
    "    \n",
    "# a dummy function that just returns its input\n",
    "def identity(x):\n",
    "    return x\n",
    "\n",
    "# reads the corpus and split to a training and test set\n",
    "X, Y = read_corpus('trainset.txt', use_sentiment=False)\n",
    "split_point = int(0.75*len(X))\n",
    "Xtrain = X[:split_point]\n",
    "Ytrain = Y[:split_point]\n",
    "Xtest = X[split_point:]\n",
    "Ytest = Y[split_point:]\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)\n",
    "\n",
    "# let's use the TF-IDF vectorizer\n",
    "tfidf = True\n",
    "\n",
    "# we use a dummy function as tokenizer and preprocessor,\n",
    "# since the texts are already preprocessed and tokenized.\n",
    "if tfidf:\n",
    "    vec = TfidfVectorizer(preprocessor = identity,\n",
    "                          tokenizer = identity)\n",
    "else:\n",
    "    vec = CountVectorizer(preprocessor = identity,\n",
    "                          tokenizer = identity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cls__alpha': 0.6}\n",
      "0.9091666666666667\n"
     ]
    }
   ],
   "source": [
    "# NAIVE BAYES\n",
    "\n",
    "\n",
    "params = {'cls__alpha': np.arange(0.5, 1.0, 0.1)}\n",
    "\n",
    "# combine the vectorizer with a Naive Bayes classifier\n",
    "classifier = Pipeline( [('vec', vec),\n",
    "                        ('cls', MultinomialNB())] )\n",
    "\n",
    "GS = GridSearchCV(classifier, params, cv=5, scoring='f1_micro')\n",
    "\n",
    "GS.fit(X, Y)\n",
    "\n",
    "print(GS.best_params_)\n",
    "print(GS.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cls__max_depth': 26}\n",
      "0.7995\n"
     ]
    }
   ],
   "source": [
    "#DECISION TREE\n",
    "\n",
    "params = {'cls__max_depth': range(10,30)}\n",
    "\n",
    "# combine the vectorizer with a Decision Tree classifier\n",
    "classifier = Pipeline( [('vec', vec),\n",
    "                        ('cls', tree.DecisionTreeClassifier())])\n",
    "\n",
    "GS = GridSearchCV(classifier, params, cv=5, scoring='f1_micro')\n",
    "\n",
    "GS.fit(X, Y)\n",
    "\n",
    "print(GS.best_params_)\n",
    "print(GS.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-NN\n",
    "\n",
    "params = {'cls__n_neighbors': range(1,50)}\n",
    "\n",
    "# combine the vectorizer with a classifier\n",
    "classifier = Pipeline( [('vec', vec),\n",
    "                        ('cls', KNeighborsClassifier()])\n",
    "GS = GridSearchCV(classifier, params, cv=5, scoring='f1_micro')\n",
    "\n",
    "GS.fit(X, Y)\n",
    "                        \n",
    "print(GS.best_params_)\n",
    "print(GS.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training time:  0.9304294586181641\n",
      "training time:  5.186425447463989\n",
      "training time:  0.8738784790039062\n"
     ]
    }
   ],
   "source": [
    "# complexity evaluation of NB, DT and KNN\n",
    "import time\n",
    "\n",
    "# combine the vectorizer with a Naive Bayes classifier\n",
    "classifier = Pipeline( [('vec', vec), ('cls', MultinomialNB())] )\n",
    "\n",
    "t0 = time.time()\n",
    "classifier.fit(X, Y)\n",
    "train_time = time.time() - t0\n",
    "print(\"training time: \", train_time)\n",
    "\n",
    "# combine the vectorizer with a Decision Tree classifier\n",
    "classifier = Pipeline( [('vec', vec),\n",
    "                        ('cls', tree.DecisionTreeClassifier())])\n",
    "\n",
    "t0 = time.time()\n",
    "classifier.fit(X, Y)\n",
    "train_time = time.time() - t0\n",
    "print(\"training time: \", train_time)\n",
    "\n",
    "\n",
    "# combine the vectorizer with a KNN classifier\n",
    "classifier = Pipeline( [('vec', vec),  ('cls', KNeighborsClassifier(n_neighbors=1))])\n",
    "\n",
    "t0 = time.time()\n",
    "classifier.fit(X, Y)\n",
    "train_time = time.time() - t0\n",
    "print(\"training time: \", train_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8036666666666666"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time:  0.21404695510864258\n",
      "test time:  0.2054767608642578\n",
      "test time:  1.3513238430023193\n"
     ]
    }
   ],
   "source": [
    "# complexity evaluation of NB, DT and KNN\n",
    "import time\n",
    "\n",
    "# combine the vectorizer with a Naive Bayes classifier\n",
    "classifier = Pipeline( [('vec', vec), ('cls', MultinomialNB())] )\n",
    "\n",
    "classifier.fit(X, Y)\n",
    "t0 = time.time()\n",
    "y_guess = classifier.predict(Xtest)\n",
    "test_time = time.time() - t0\n",
    "print(\"test time: \", test_time)\n",
    "\n",
    "# combine the vectorizer with a Decision Tree classifier\n",
    "classifier = Pipeline( [('vec', vec),\n",
    "                        ('cls', tree.DecisionTreeClassifier())])\n",
    "\n",
    "\n",
    "classifier.fit(X, Y)\n",
    "t0 = time.time()\n",
    "y_guess = classifier.predict(Xtest)\n",
    "\n",
    "test_time = time.time() - t0\n",
    "print(\"test time: \", test_time)\n",
    "\n",
    "\n",
    "# combine the vectorizer with a KNN classifier\n",
    "classifier = Pipeline( [('vec', vec),  ('cls', KNeighborsClassifier(n_neighbors=1))])\n",
    "\n",
    "classifier.fit(X, Y)\n",
    "t0 = time.time()\n",
    "y_guess = classifier.predict(Xtest)\n",
    "test_time = time.time() - t0\n",
    "print(\"test time: \", test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'DecisionTreeClassifier'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-f6436bc61a64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                   'max_features': [1, 2, 3, 4]}\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdecision_tree_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcross_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'DecisionTreeClassifier'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
